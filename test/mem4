import AVFoundation

func extractAudioFromMP4(videoFilePath: String, wavFilePath: String) -> Bool {
    let asset = AVAsset(url: URL(fileURLWithPath: videoFilePath))
    
    guard let audioTrack = asset.tracks(withMediaType: .audio).first else {
        print("未找到音频轨道")
        return false
    }
    
    let outputSettings: [String: Any] = [
        AVFormatIDKey: kAudioFormatLinearPCM,
        AVLinearPCMIsFloatKey: false,
        AVLinearPCMIsBigEndianKey: false,
        AVLinearPCMBitDepthKey: 16,
        AVLinearPCMIsNonInterleaved: false
    ]
    
    let outputURL = URL(fileURLWithPath: wavFilePath)
    
    do {
        let assetReader = try AVAssetReader(asset: asset)
        let trackOutput = AVAssetReaderTrackOutput(track: audioTrack, outputSettings: outputSettings)
        
        assetReader.add(trackOutput)
        
        assetReader.startReading()
        
        let fileOutput = FileHandle(forWritingAtPath: wavFilePath)
        fileOutput?.truncateFile(atOffset: 0)
        
        guard let audioFormat = audioTrack.formatDescriptions.first as? CMAudioFormatDescription else {
            print("无法获取音频格式描述")
            return false
        }
        
        let asbd = CMAudioFormatDescriptionGetStreamBasicDescription(audioFormat)?.pointee
        
        let channels = asbd?.mChannelsPerFrame ?? 0
        let sampleRate = asbd?.mSampleRate ?? 0
        
        let audioFormatSettings: [String: Any] = [
            AVFormatIDKey: kAudioFormatLinearPCM,
            AVSampleRateKey: sampleRate,
            AVNumberOfChannelsKey: channels,
            AVLinearPCMBitDepthKey: 16,
            AVLinearPCMIsNonInterleaved: false,
            AVLinearPCMIsFloatKey: false,
            AVLinearPCMIsBigEndianKey: false
        ]
        
        let audioFormat = AVAudioFormat(settings: audioFormatSettings)
        let audioFile = try AVAudioFile(forWriting: outputURL, settings: audioFormat!.settings)
        
        while let sampleBuffer = trackOutput.copyNextSampleBuffer() {
            let presentationTimeStamp = CMSampleBufferGetOutputPresentationTimeStamp(sampleBuffer)
            
            guard let audioBuffer = CMSampleBufferGetDataBuffer(sampleBuffer) else {
                print("无法获取 PCM 缓冲区")
                return false
            }
            
            var blockBuffer: CMBlockBuffer?
            var audioBufferList = AudioBufferList(
                mNumberBuffers: 1,
                mBuffers: AudioBuffer(
                    mNumberChannels: UInt32(channels),
                    mDataByteSize: CMBlockBufferGetDataLength(audioBuffer),
                    mData: nil
                )
            )
            
            let status = CMSampleBufferGetAudioBufferListWithRetainedBlockBuffer(
                sampleBuffer,
                bufferListSizeNeededOut: nil,
                bufferListOut: &audioBufferList,
                bufferListSize: MemoryLayout<AudioBufferList>.size,
                blockBufferAllocator: nil,
                blockBufferMemoryAllocator: nil,
                flags: kCMSampleBufferFlag_AudioBufferList_Assure16ByteAlignment,
                blockBufferOut: &blockBuffer
            )
            
            guard status == 0 else {
                print("无法获取 PCM 缓冲区")
                return false
            }
            
            let audioBufferData = Data(bytes: audioBufferList.mBuffers.mData!, count: Int(audioBufferList.mBuffers.mDataByteSize))
            
            let audioBufferPCM = AVAudioPCMBuffer(pcmFormat: audioFormat!, frameCapacity: UInt32(audioBufferData.count) / audioFormat!.streamDescription.pointee.mBytesPerFrame)
            
            audioBufferPCM?.frameLength = audioBufferPCM!.frameCapacity
            audioBufferData.copyBytes(to: UnsafeMutableBufferPointer(start: audioBufferPCM!.int16ChannelData![0], count: audioBufferData.count / MemoryLayout<Int16>.size))
            
            try audioFile.write(from: audioBufferPCM!)
            
            CMSampleBufferInvalidate(sampleBuffer)
        }
        
        assetReader.cancelReading()
        fileOutput?.closeFile()
        
        print("音频已解码并保存为 WAV 文件：\(wavFilePath)")
        return true
    } catch {
        print("音频解码失败：\(error)")
        return false
    }
}

// 使用示例
let videoFilePath = "path/to/inputfile.mp4"
let wavFilePath = "path/to/outputfile.wav"

let extractionSuccess = extractAudioFromMP4(videoFilePath: videoFilePath, wavFilePath: wavFilePath)
if extractionSuccess {
    print("音频提取和解码成功")
} else {
    print("音频提取和解码失败")
}
